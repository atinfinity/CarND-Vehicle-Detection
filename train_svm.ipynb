{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vehicleDetectUtil as vehicleUtil\n",
    "import vehicleDetect_svmVar as svmVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    files_vehicle = glob.glob('vehicles/**/*.png', recursive=True)\n",
    "    files_nonVehicle = glob.glob('non-vehicles/**/*.png', recursive=True)\n",
    "\n",
    "    img = cv2.imread(files_vehicle[0])\n",
    "    imgShape = img.shape\n",
    "\n",
    "    #if svm:\n",
    "    t=time.time()        \n",
    "    files_vehicle_svm = files_vehicle\n",
    "    files_nonVehicle_svm = files_nonVehicle\n",
    "    print('SVM: using {} car and {} non-car images'.format(len(files_vehicle_svm), len(files_nonVehicle_svm)))\n",
    "    print('SVM: preparing features...')\n",
    "    car_features = vehicleUtil.extract_features(files_vehicle_svm, cspace=svmVar.spatial_clr, spatial_size=(svmVar.spatial, svmVar.spatial),\n",
    "                            hist_bins=svmVar.histbin, hist_range=(0, 256), spatialFeat = svmVar.spatialFeat, histFeat = svmVar.histFeat,\n",
    "                            hogFeat=svmVar.hogFeat, hog_cspace=svmVar.hog_clrspace, hog_orient=svmVar.orient, hog_pix_per_cell=svmVar.pix_per_cell, hog_cell_per_block=svmVar.cell_per_block, hog_channel=svmVar.hog_channel)\n",
    "    notcar_features = vehicleUtil.extract_features(files_nonVehicle_svm, cspace=svmVar.spatial_clr, spatial_size=(svmVar.spatial, svmVar.spatial),\n",
    "                            hist_bins=svmVar.histbin, hist_range=(0, 256), spatialFeat = svmVar.spatialFeat, histFeat = svmVar.histFeat,\n",
    "                            hogFeat=svmVar.hogFeat, hog_cspace=svmVar.hog_clrspace, hog_orient=svmVar.orient, hog_pix_per_cell=svmVar.pix_per_cell, hog_cell_per_block=svmVar.cell_per_block, hog_channel=svmVar.hog_channel)\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    print('SVM: normalizing features...')\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "        \n",
    "    # singular value decomposition to reduce feature space\n",
    "    pca = decomposition.PCA(n_components=3000)\n",
    "    pca.fit(scaled_X)\n",
    "    scaled_X = pca.transform(scaled_X)\n",
    "\n",
    "    # Define the labels vector\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "    t2=time.time()\n",
    "    print('{} seconds to create {} feature vectors of size {}'.format(round(t2-t, 5), len(scaled_X), len(scaled_X[0])))\n",
    "    print('SVM: splitting train/validation data...')\n",
    "    rand_state = np.random.randint(0, 100)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.1, random_state=rand_state)\n",
    "\n",
    "    print('SVM: Training model...')\n",
    "    svc = LinearSVC()\n",
    "    # Check the training time for the SVC\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2-t, 2), 'Seconds to train SVM...')\n",
    "    print('SVM: Saving model...')\n",
    "    joblib.dump(svc, 'svm.pkl')\n",
    "    joblib.dump(X_scaler, 'svm_scaler.pkl')\n",
    "    joblib.dump(pca, 'svm_pca.pkl')\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: using 8792 car and 8968 non-car images\n",
      "SVM: preparing features...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/skimage/feature/_hog.py:119: skimage_deprecation: Default value of `block_norm`==`L1` is deprecated and will be changed to `L2-Hys` in v0.15\n",
      "  'be changed to `L2-Hys` in v0.15', skimage_deprecation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM: normalizing features...\n",
      "193.10004 seconds to create 17760 feature vectors of size 3000\n",
      "SVM: splitting train/validation data...\n",
      "SVM: Training model...\n",
      "6.63 Seconds to train SVM...\n",
      "SVM: Saving model...\n",
      "Test Accuracy of SVC =  0.9927\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
